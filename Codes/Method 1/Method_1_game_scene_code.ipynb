{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txTGz2YObRtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bbde9c-c9db-45b1-a89d-4d2ced8df34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image preprocessing complete!\n"
          ]
        }
      ],
      "source": [
        "# Import Required libraries\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Replace with the path to your root directory containing the emotion folders\n",
        "root_dir = '/content/drive/MyDrive/Untitled folder/Custom dataset/Game scne/Train'\n",
        "\n",
        "# Replace with the desired output directory\n",
        "output_dir = '/content/drive/MyDrive/Untitled folder/Custom dataset/Game scne/Test4'\n",
        "\n",
        "\n",
        "# Function to preprocess an image\n",
        "def preprocess_image(img_path):\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "  img = cv2.resize(img, (150, 100))\n",
        "  return img\n",
        "\n",
        "# Iterate through each emotion folder\n",
        "for emotion_folder in os.listdir(root_dir):\n",
        "    emotion_path = os.path.join(root_dir, emotion_folder)\n",
        "\n",
        "    # Create output folder for the emotion\n",
        "    output_emotion_path = os.path.join(output_dir, emotion_folder)\n",
        "    os.makedirs(output_emotion_path, exist_ok=True)\n",
        "\n",
        "    # Iterate through images in the emotion folder\n",
        "    for image_file in os.listdir(emotion_path):\n",
        "        image_path = os.path.join(emotion_path, image_file)\n",
        "\n",
        "        # Preprocess the image\n",
        "        preprocessed_img = preprocess_image(image_path)\n",
        "\n",
        "        # Save the preprocessed image in the output folder\n",
        "        output_file = os.path.join(output_emotion_path, image_file)\n",
        "        cv2.imwrite(output_file, preprocessed_img)\n",
        "\n",
        "print(\"Image preprocessing complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2  # Make sure to import cv2 for image processing\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Replace with the path to your preprocessed data directory\n",
        "data_dir = r'/content/drive/MyDrive/Untitled folder/Custom dataset/Game scne/Test4'  # Use raw string\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 150,100\n",
        "batch_size = 12\n",
        "test_size = 0.20\n",
        "\n",
        "# Load and preprocess data\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for emotion_folder in os.listdir(data_dir):\n",
        "    emotion_path = os.path.join(data_dir, emotion_folder)\n",
        "    for image_file in os.listdir(emotion_path):\n",
        "        image_path = os.path.join(emotion_path, image_file)\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (img_width, img_height))  # Ensure image is resized\n",
        "        img = img.reshape((img_height, img_width, 1))\n",
        "        data.append(img)\n",
        "        labels.append(emotion_folder)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=152)\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "print(\"Creating the CNN model...\")\n",
        "model2 = Sequential([\n",
        "    Input(shape=(img_height, img_width, 1)),  # Use Input layer\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "print(\"Compiling the model...\")\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with a smaller batch size if necessary\n",
        "print(\"Starting model training...\")\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# adjusting learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-3)\n",
        "\n",
        "#train model\n",
        "history = model2.fit(\n",
        "    train_datagen.flow(X_train, y_train, batch_size=16),  # Adjusted batch size\n",
        "    epochs=15,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model2.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Predict emotions from a new image\n",
        "new_img = cv2.imread('/content/drive/MyDrive/Untitled folder/Custom dataset/Game scne/Test2/Disgust/Ankita_1.png', cv2.IMREAD_GRAYSCALE)\n",
        "new_img = cv2.resize(new_img, (img_width, img_height))\n",
        "new_img = np.expand_dims(new_img, axis=0)\n",
        "new_img = new_img / 255.0\n",
        "\n",
        "predicted_emotion = le.inverse_transform(np.argmax(model2.predict(new_img), axis=-1))[0]\n",
        "print(\"Predicted emotion:\", predicted_emotion)"
      ],
      "metadata": {
        "id": "Q5h62hgOrzNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1fc412-a118-4982-b9eb-4398e3d6795b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the CNN model...\n",
            "Compiling the model...\n",
            "Starting model training...\n",
            "Epoch 1/15\n",
            "10/10 [==============================] - 2s 74ms/step - loss: 163.0478 - accuracy: 0.1299 - val_loss: 2.2450 - val_accuracy: 0.4359 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.8109 - accuracy: 0.2987 - val_loss: 1.7563 - val_accuracy: 0.2564 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 1.7495 - accuracy: 0.3247 - val_loss: 1.5731 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.7017 - accuracy: 0.2727 - val_loss: 1.5656 - val_accuracy: 0.3590 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 1.6965 - accuracy: 0.3312 - val_loss: 1.5391 - val_accuracy: 0.3590 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 1.6726 - accuracy: 0.3117 - val_loss: 1.5231 - val_accuracy: 0.3590 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.6758 - accuracy: 0.3312 - val_loss: 1.4939 - val_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 1.6591 - accuracy: 0.3506 - val_loss: 1.4586 - val_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.6511 - accuracy: 0.3506 - val_loss: 1.4282 - val_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 1.6420 - accuracy: 0.3377 - val_loss: 1.4011 - val_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.5970 - accuracy: 0.3766 - val_loss: 1.4073 - val_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.5867 - accuracy: 0.3636 - val_loss: 1.4033 - val_accuracy: 0.4359 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.5789 - accuracy: 0.3571 - val_loss: 1.3706 - val_accuracy: 0.4359 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.5285 - accuracy: 0.3896 - val_loss: 1.3458 - val_accuracy: 0.4359 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.4937 - accuracy: 0.3831 - val_loss: 1.3066 - val_accuracy: 0.4872 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.3066 - accuracy: 0.4872\n",
            "Test accuracy: 0.4871794879436493\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Predicted emotion: happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2  # Make sure to import cv2 for image processing\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Replace with the path to your preprocessed data directory\n",
        "data_dir = r'/content/drive/MyDrive/Untitled folder/Custom dataset/Game scne/Test4'\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 150,100\n",
        "batch_size = 12\n",
        "test_size = 0.20\n",
        "\n",
        "# Load and preprocess data\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for emotion_folder in os.listdir(data_dir):\n",
        "    emotion_path = os.path.join(data_dir, emotion_folder)\n",
        "    for image_file in os.listdir(emotion_path):\n",
        "        image_path = os.path.join(emotion_path, image_file)\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (img_width, img_height))  # Ensure image is resized\n",
        "        img = img.reshape((img_height, img_width, 1))\n",
        "        data.append(img)\n",
        "        labels.append(emotion_folder)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=48)\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "print(\"Creating the CNN model...\")\n",
        "model3 = Sequential([\n",
        "    Input(shape=(img_height, img_width, 1)),  # Use Input layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "print(\"Compiling the model...\")\n",
        "model3.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with a smaller batch size if necessary\n",
        "print(\"Starting model training...\")\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# adjusting learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-3)\n",
        "\n",
        "#train model\n",
        "history = model3.fit(\n",
        "    train_datagen.flow(X_train, y_train, batch_size=16),  # Adjusted batch size\n",
        "    epochs=20,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model3.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Predict emotions from a new image\n",
        "new_img = cv2.imread('/content/drive/MyDrive/Untitled folder/Custom dataset/Game scne/Test2/Disgust/Ankita_1.png', cv2.IMREAD_GRAYSCALE)\n",
        "new_img = cv2.resize(new_img, (img_width, img_height))\n",
        "new_img = np.expand_dims(new_img, axis=0)\n",
        "new_img = new_img / 255.0\n",
        "\n",
        "predicted_emotion = le.inverse_transform(np.argmax(model2.predict(new_img), axis=-1))[0]\n",
        "print(\"Predicted emotion:\", predicted_emotion)"
      ],
      "metadata": {
        "id": "7prM1JQ8BMQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8cf0b2b-5c9c-4b56-d331-fc5cb8e62a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the CNN model...\n",
            "Compiling the model...\n",
            "Starting model training...\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 3s 181ms/step - loss: 348.8248 - accuracy: 0.1818 - val_loss: 1.9715 - val_accuracy: 0.2051 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 3.4266 - accuracy: 0.2727 - val_loss: 12.8129 - val_accuracy: 0.2564 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 2.8069 - accuracy: 0.4156 - val_loss: 1.2195 - val_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 2.1578 - accuracy: 0.3961 - val_loss: 1.3326 - val_accuracy: 0.5641 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 1s 147ms/step - loss: 2.1088 - accuracy: 0.3442 - val_loss: 1.3169 - val_accuracy: 0.4872 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 2s 150ms/step - loss: 1.5662 - accuracy: 0.3896 - val_loss: 1.1590 - val_accuracy: 0.6154 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 1.3700 - accuracy: 0.5195 - val_loss: 0.9501 - val_accuracy: 0.5128 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 2.8044 - accuracy: 0.3896 - val_loss: 4.6722 - val_accuracy: 0.2308 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 2.6890 - accuracy: 0.3766 - val_loss: 1.3909 - val_accuracy: 0.4615 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.4928 - accuracy: 0.4481 - val_loss: 1.0899 - val_accuracy: 0.4615 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 1s 147ms/step - loss: 1.3991 - accuracy: 0.4805 - val_loss: 1.2576 - val_accuracy: 0.5128 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 2.8109 - accuracy: 0.3831 - val_loss: 0.9019 - val_accuracy: 0.5897 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 2.3056 - accuracy: 0.4740 - val_loss: 1.0531 - val_accuracy: 0.5897 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.3258 - accuracy: 0.4675 - val_loss: 0.7535 - val_accuracy: 0.6923 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 2s 150ms/step - loss: 1.8383 - accuracy: 0.5455 - val_loss: 0.8880 - val_accuracy: 0.6410 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 1.2489 - accuracy: 0.5390 - val_loss: 13.5485 - val_accuracy: 0.2821 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 34.3648 - accuracy: 0.3312 - val_loss: 2.0406 - val_accuracy: 0.4615 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 1.5959 - accuracy: 0.4740 - val_loss: 0.8581 - val_accuracy: 0.7179 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 2.2401 - accuracy: 0.4740 - val_loss: 0.8334 - val_accuracy: 0.7949 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.6361 - accuracy: 0.4286 - val_loss: 0.6856 - val_accuracy: 0.7179 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6856 - accuracy: 0.7179\n",
            "Test accuracy: 0.7179487347602844\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Predicted emotion: Disgust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to a file\n",
        "model3.save('Model3Custom_CK.h5', save_format='h5')\n",
        "# Save the model to a file\n",
        "model3.save('Model3Custom_CK.keras')  # Save as a single HDF5 file  # Save as a single HDF5 file"
      ],
      "metadata": {
        "id": "wWlBrknso-ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zad2XPFKvFKN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}